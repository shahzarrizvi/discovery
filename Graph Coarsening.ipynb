{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Coarsening #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from condensation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores a method for graph coarsening utilizing an [inhomogeneous diffusion condensation](https://arxiv.org/abs/1907.04463) algorithm which has already shown success in the coarse graining of data.\n",
    "\n",
    "The goal of graph coarsening is to take a very complex graph—one with many nodes and many connections—and \"condense\" the graph by combining similar nodes into one another. The result of graph coarsening is a coarsened graph consisting of supernodes with edges between them, where the supernodes are linear combinations of the nodes in the original graph, and the edges maintain the connections from the original graph.\n",
    "\n",
    "At the same time, we would like to maintain a kernel throughout the coarsening of this graph. In general, a kernel is a function which specifies the similarities between two datapoints; this \"similarity function\" acts as an inner product over the set of datapoints. For machine learning purposes, defining a kernel on a graph is desirable. One such graph kernel is called the marginalized graph kernel and finds the similarity between two graphs by comparing the similarities of random walks on both graphs. Such a graph kernel requires a nodel kernel and an edge kernel (kernel functions computing the similarities between nodes and edges). Since the original nodes of the graph are condensed over the course of the graph coarsening, a node kernel must be defined at each step of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhomogeneous Diffusion Condensation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first explore the process of inhomogeneous diffusion condensation. \n",
    "\n",
    "This is a clustering algorithm similar to $k$-means or agglomerative clustering which seeks to find a hierarchical coarse-grained representation of the data. The algorithm works by computing a diffusion operator $\\mathbf{P}$ (consisting of the transition matrix of a Markovian random walk over the data) and repeatedly applying it to the data.\n",
    "\n",
    "The details of the algorithm are unimportant, but it is interesting to apply it to various datasets. Here, we have eight datasets (``barbell``, ``tree``, ``noisy tree``, ``clusters``, ``uniform circle``, ``hyperuniform circle``, ``hyperuniform ellipse``, and ``two spirals``) on which we can apply the diffusion condensation algorithm. These datasets come from this [github repository](https://github.com/matthew-hirn/condensation) on inhomogeneous diffusion condensation.\n",
    "\n",
    "The datasets are visualized below for ``N`` points. You can change ``N`` and run the cell to see the datasets with a different amount of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2 ** 7\n",
    "\n",
    "plot_datasets(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are familiar with the datasets, we can run the condensation algorithm on them. The condensation algorithm will effectively run until all the data has been condensed into a single point. The code below will run through ``num_steps`` timesteps. To see the algorithm run until completion, set ``num_steps`` to ``math.inf``.\n",
    "\n",
    "Pick one of the datasets above and a number of points ``N``. Assign them to the ``dataset`` and ``N`` variables below, respectively, and run the cell to see the condensation process on that dataset. It may take a couple of minutes for the plots to load. If it is taking too long, try decreasing ``N``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'barbell'\n",
    "N = 2 ** 7\n",
    "\n",
    "make_plots(dataset, N, num_steps = 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Coarsening ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same diffusion process can be applied to graphs. By condensing the adjacency matrix of a graph and extracting the projections of the nodes from the condensed adjacency matrix using an eigendecomposition, supernodes, represented as eigenvectors, can be recovered. They are represented as linear combinations of the existing nodes in the graph.\n",
    "\n",
    "Once the supernode representation of the graph as been recovered, the node kernel between supernodes can be reconstructed using the marginalized graph kernel of the original graph itself. The marginalized graph kernel between two graphs is computed using a neighborhood similarity matrix $V_{\\times}r_{\\infty}$, which represents the similarities between the spanning trees of two nodes. The similarity between two supernodes is the weighted sum over neighborhood similarities of the nodes inside each supernode.\n",
    "\n",
    "This notebook has 3 graphs, $G_0$, $G_1$, and $G_2$. \n",
    "\n",
    "$G_0$ is a simple graph on two vertices.\n",
    "![G0](graphs/G0.png)\n",
    "\n",
    "$G_1$ is a slightly more complex graph. It is defined on four vertices.\n",
    "![G1](graphs/G1.png)\n",
    "\n",
    "$G_2$ is a randomly generated graph on ten vertices. The cell below visualizes the adjacency matrices of the three graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_adj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the $V_{\\times}r_{\\infty}$ similarities as matrices on each of the graphs. These define a notion of similarity between nodes in the context of the graph, and can be used to construct the node kernel of the coarsened graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_z()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
